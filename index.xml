<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>吕超阳的博客</title><link>https://georgelyu.github.io/</link><description>Recent content on 吕超阳的博客</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Tue, 25 Mar 2025 14:23:56 +0800</lastBuildDate><atom:link href="https://georgelyu.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>通过 MMA 使用 NVIDIA GPU 的 Tensor Core</title><link>https://georgelyu.github.io/p/tensor_core_ptx/</link><pubDate>Tue, 25 Mar 2025 14:23:56 +0800</pubDate><guid>https://georgelyu.github.io/p/tensor_core_ptx/</guid><description>&lt;p>本篇文章主要讲如何通过 &lt;code>mma&lt;/code> ptx 语句来调用 NVIDIA GPU 的 Tensor Core。&lt;/p>
&lt;h2 id="主要概念">主要概念
&lt;/h2>&lt;p>Tensor Core 执行的是 M-by-N-by-K 的矩阵操作 &lt;code>D = op(A, B) + C&lt;/code>，这里使用的是 BLAS 的定义，即 &lt;code>A&lt;/code> 矩阵的维度是 &lt;code>M x K&lt;/code>，&lt;code>B&lt;/code> 矩阵的维度是 &lt;code>K x N&lt;/code>，&lt;code>C&lt;/code> 和 &lt;code>D&lt;/code> 矩阵的维度是 &lt;code>M x N&lt;/code>。我们把 &lt;code>[M, N, K]&lt;/code> 的组合称为 shape。&lt;/p></description></item><item><title>在 CUDA 中使用 PTX</title><link>https://georgelyu.github.io/p/ptx/</link><pubDate>Tue, 25 Mar 2025 14:23:56 +0800</pubDate><guid>https://georgelyu.github.io/p/ptx/</guid><description>&lt;p>以下内容翻译自 &lt;a class="link" href="https://docs.nvidia.com/cuda/inline-ptx-assembly/index.html" target="_blank" rel="noopener"
>CUDA 官方的 PTX 使用说明&lt;/a>，并进行了一些整理。&lt;/p>
&lt;h2 id="asm-命令">ASM 命令
&lt;/h2>&lt;p>我们从 ASM 指令的格式讲起，ASM 指令的格式如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c++" data-lang="c++">&lt;span class="line">&lt;span class="cl">&lt;span class="k">asm&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;template-string&amp;#34;&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="s">&amp;#34;constraint&amp;#34;&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">output&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="s">&amp;#34;constraint&amp;#34;&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">input&lt;/span>&lt;span class="p">));&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>一条简单的 ASM 语句如下所示：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c++" data-lang="c++">&lt;span class="line">&lt;span class="cl">&lt;span class="k">asm&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;add.s32 %0, %1, %2;&amp;#34;&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="s">&amp;#34;=r&amp;#34;&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="s">&amp;#34;r&amp;#34;&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">j&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="s">&amp;#34;r&amp;#34;&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">k&lt;/span>&lt;span class="p">));&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>从这个格式和示例，我们可以注意到以下两点：&lt;/p></description></item><item><title>设计模式总结</title><link>https://georgelyu.github.io/p/design_p_atterns/</link><pubDate>Fri, 21 Mar 2025 16:00:12 +0800</pubDate><guid>https://georgelyu.github.io/p/design_p_atterns/</guid><description>&lt;p>一直感觉没有系统地梳理过设计模式，依据&lt;a class="link" href="https://github.com/kamranahmedse/design-patterns-for-humans" target="_blank" rel="noopener"
>Design patterns for humans&lt;/a>和一个非常好的&lt;a class="link" href="https://segmentfault.com/a/1190000010706695#item-4-25" target="_blank" rel="noopener"
>翻译版&lt;/a>，我在这里简要地梳理一下这些设计模式的本质。&lt;/p>
&lt;h2 id="概述">概述
&lt;/h2>&lt;p>最早的设计模式中有一些其实可能在现在已经太普遍了很难让人觉得是设计模式，或者有一些可能会被认为只是对一类编程技巧的称呼，只是因为用到了 OOP 特性变成了设计模式，还有一些甚至已经被语言吸收变成语言特性了。所以在这里先进行一个总结性的分类。&lt;/p></description></item><item><title>CUDA Softmax 优化</title><link>https://georgelyu.github.io/p/cuda_softmax_opt/</link><pubDate>Fri, 14 Mar 2025 14:57:27 +0800</pubDate><guid>https://georgelyu.github.io/p/cuda_softmax_opt/</guid><description>&lt;p>在这里记录一下关于 softmax 函数的 CUDA 实现的优化，基本翻译自 Maharshi Pandya 的 &lt;a class="link" href="https://maharshi.bearblog.dev/optimizing-softmax-cuda/" target="_blank" rel="noopener"
>Learning CUDA by optimizing softmax: A worklog&lt;/a> 这篇博客。&lt;/p>
&lt;h2 id="softmax-的定义">Softmax 的定义
&lt;/h2>&lt;p>Softmax 函数的输入是一个有 $N$ 个元素的数组 $X = \{ x_i \}$，输出是同样的一个有 N 个元素的数组 $O = \{ o_i \}$，第 $i$ 个输出元素 $o_i$ 的定义如下：&lt;/p></description></item><item><title>CUDA Bank Conflict 的解决方法</title><link>https://georgelyu.github.io/p/cuda_bank_conflict/</link><pubDate>Thu, 06 Mar 2025 15:19:00 +0800</pubDate><guid>https://georgelyu.github.io/p/cuda_bank_conflict/</guid><description>&lt;p>&lt;a class="link" href="https://leimao.github.io/blog/CUDA-Shared-Memory-Bank/" target="_blank" rel="noopener"
>CUDA shared memory bank conflict&lt;/a> 是会造成 shared memory 访问延迟的一个原因。这篇主要介绍两种消除 CUDA bank confict 的方法，分别为 memory padding 与 swizzling。&lt;/p>
&lt;p>我们以矩阵转置为例，如果我们设定 block 的大小为 $32 \times 32$，每个 block 对 GMEM 中这个矩阵 $32 \times 32$ 的一小块进行转置。则这个 block 中的线程需要集体从 GMEM 中将矩阵搬运至 SMEM（不转置的搬运），并在转置后存储到 GMEM。注意在 SMEM 中，矩阵是没有转置的。所以在后面存储至 GMEM 时，我们需要一次读取 SMEM 中的一列数据，写入 GMEM 的一行中。&lt;/p></description></item><item><title>《Cooperative Groups Flexible CUDA Thread Programming》笔记</title><link>https://georgelyu.github.io/p/cuda_cooperative_groups/</link><pubDate>Tue, 04 Mar 2025 14:26:36 +0800</pubDate><guid>https://georgelyu.github.io/p/cuda_cooperative_groups/</guid><description>&lt;p>这是&lt;a class="link" href="https://developer.nvidia.com/blog/cooperative-groups/" target="_blank" rel="noopener"
>《Cooperative Groups: Flexible CUDA Thread Programming》&lt;/a>这篇博客的学习笔记。&lt;/p>
&lt;h2 id="动机">动机
&lt;/h2>&lt;p>在 CUDA 中线程之间分享数据和协作工作是非常常见的。CUDA 为此提供了一个同步函数 &lt;code>__syncthreads()&lt;/code>，但是这个函数只能在 block 间同步。有时我们会需要更细粒度的线程协作。&lt;/p></description></item><item><title>《Beyond Floating Point Next-Generation Computer Arithmetic》笔记</title><link>https://georgelyu.github.io/p/posit_arithmetic/</link><pubDate>Mon, 03 Mar 2025 15:47:50 +0800</pubDate><guid>https://georgelyu.github.io/p/posit_arithmetic/</guid><description>&lt;p>由于读博士期间不停地被浮点数精度所折磨，所以想要学习相关的内容。这里记录关于 posit 格式——作者认为可以用来替换 IEEE 754 浮点数的格式——的学习笔记。下面是 2017 年该论文的作者之一 Dr. John L. Gustafson 在斯坦福进行的演讲。该演讲是斯坦福 EE 计算机系统课程的一部分（实名羡慕）。&lt;/p></description></item><item><title>《Better Performance at Lower Occupancy》笔记</title><link>https://georgelyu.github.io/p/lower_occupancy_note/</link><pubDate>Sun, 23 Feb 2025 13:02:52 +0800</pubDate><guid>https://georgelyu.github.io/p/lower_occupancy_note/</guid><description>&lt;p>因为在实践过程中发现，occupancy 的高低似乎与性能没有绝对的联系，十分想探明背后的原因，所以进行了一番查询，找到了 &lt;a class="link" href="https://www.nvidia.com/content/gtc-2010/pdfs/2238_gtc2010.pdf" target="_blank" rel="noopener"
>Better Performance at Lower Occupancy&lt;/a> 这个 talk（下面简称 talk）。这里是阅读并学习这一 talk 的笔记。&lt;/p></description></item><item><title>CUDA GEMM 优化</title><link>https://georgelyu.github.io/p/cuda_gemm_opt/</link><pubDate>Sat, 22 Feb 2025 21:32:50 +0800</pubDate><guid>https://georgelyu.github.io/p/cuda_gemm_opt/</guid><description>&lt;p>因为最近读完了《Programming Massively Parallel Processors: A Hands-on Approach (4th Edition)》这本书（下面简称 PMPP），非常想结合书中的内容实操一下。&lt;/p>
&lt;p>所以我结合了 &lt;a class="link" href="https://zhuanlan.zhihu.com/p/478846788" target="_blank" rel="noopener"
>cuda 入门的正确姿势：how-to-optimize-gemm&lt;/a> 和 &lt;a class="link" href="https://siboehm.com/articles/22/CUDA-MMM" target="_blank" rel="noopener"
>How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog&lt;/a> 这两篇非常好的文章，自己结合 PMPP 中的经验写了一版代码，同时记录一下学习的过程。&lt;/p></description></item><item><title>存档</title><link>https://georgelyu.github.io/archives/</link><pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate><guid>https://georgelyu.github.io/archives/</guid><description/></item><item><title>搜索</title><link>https://georgelyu.github.io/search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://georgelyu.github.io/search/</guid><description/></item></channel></rss>